{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdrh.histogram import HdrHistogram\n",
    "import seaborn as sns\n",
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "import os.path\n",
    "from enum import Enum\n",
    "import matplotlib as mpl\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the dumps, do something like this\n",
    "```fish\n",
    "for GC in Serial Parallel G1 Z Shenandoah; taskset -c 0-7 /usr/lib/jvm/temurin-17-amd64/bin/java -server -XX:-TieredCompilation -Xcomp -XX:+UnlockExperimentalVMOptions -XX:+Use{$GC}GC -XX:ConcGCThreads=4 -XX:ParallelGCThreads=4 -Xms420M -Xmx420M -jar /usr/share/benchmarks/dacapo/dacapo-evaluation-git-29a657f.jar -n 5 lusearch -t 4 --dump-latency; mv scratch scratch-$GC; end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatencyType(Enum):\n",
    "    METERED = 'metered'\n",
    "    SIMPLE = 'simple'\n",
    "\n",
    "LATENCY_TYPE = LatencyType.METERED\n",
    "\n",
    "\n",
    "RUNID = 'deer-2022-03-05-Sat-171625'\n",
    "HFAC = 3023\n",
    "HEAP = {\n",
    "    'lusearch': 160,\n",
    "    'cassandra': 795,\n",
    "    'h2':  3601,\n",
    "    'tomcat': 215,\n",
    "}\n",
    "DACAPO = 'dacapochopin-29a657f'\n",
    "\n",
    "\n",
    "# SAVE_FILE = 'pdf'\n",
    "# SAVE_FILE = 'jpg'\n",
    "SAVE_FILE = None\n",
    "\n",
    "\n",
    "DATA = {\n",
    "    'LXR-Old': '{runid}/{bench}.{hfac}.{heap}.jdk-lxr-old.ix.common.tph.mmtk_perf.nr-1.latency.{dacapo}',\n",
    "    'LXR': '{runid}/{bench}.{hfac}.{heap}.jdk-lxr.ix.common.tph.mmtk_perf.oevac.latency.{dacapo}',\n",
    "    'G1': '{runid}/{bench}.{hfac}.{heap}.jdk-lxr.g1.common.hs_perf.latency.{dacapo}',\n",
    "    'G1-Default': '{runid}/{bench}.{hfac}.{heap}.jdk-lxr.g1_default.common.hs_perf.latency.{dacapo}',\n",
    "    'Shen.': '{runid}/{bench}.{hfac}.{heap}.jdk-lxr.shenandoah.common.hs_perf.latency.{dacapo}',\n",
    "    'ZGC': '{runid}/{bench}.{hfac}.{heap}.jdk-lxr.z.common.hs_perf.latency.{dacapo}',\n",
    "}\n",
    "MAX_INVOCATIONS = 40\n",
    "MIN_LATENCY_USEC = 1\n",
    "MAX_LATENCY_USEC = 1000 * 1000 # 1 sec\n",
    "LATENCY_SIGNIFICANT_DIGITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(invocation: int, latency_type: LatencyType, folder: str):\n",
    "    path = os.path.realpath(os.path.expanduser('{}.{}/dacapo-latency-usec-{}.csv'.format(folder, invocation, latency_type.value)))\n",
    "    if not os.path.isfile(path):\n",
    "        return None\n",
    "    df =  pandas.read_csv(path, names=[\"start\", \"end\"])\n",
    "    df[\"latency\"] = df[\"end\"] - df[\"start\"]\n",
    "    return df\n",
    "\n",
    "def load_data_and_plot(bench, data: Optional[Dict[str, Union[str, List[str]]]] = None, invocations = MAX_INVOCATIONS, save = SAVE_FILE, latency_type: LatencyType = LATENCY_TYPE):\n",
    "    assert bench in HEAP\n",
    "    print(f'[{bench}] Loading...')\n",
    "    histograms = {}\n",
    "    # Clean up inputs\n",
    "    if data is None:\n",
    "        data = { k: v for k, v in DATA.items() }\n",
    "    for gc in data.keys():\n",
    "        if isinstance(data[gc], str):\n",
    "            data[gc] = [ data[gc] ]\n",
    "        data[gc] = [\n",
    "            f'~/MMTk-Dev/evaluation/results/log/{x}'.format(runid=RUNID, bench=bench, hfac=HFAC, heap=HEAP[bench], dacapo=DACAPO)\n",
    "            for x in data[gc]\n",
    "        ]\n",
    "    data: Dict[str, List[str]]\n",
    "    # Load data\n",
    "    for gc, logs in data.items():\n",
    "        histograms[gc] = []\n",
    "        for folder in logs:\n",
    "            for i in range(invocations):\n",
    "                loaded_data = load_data(i, latency_type, folder)\n",
    "                if loaded_data is None:\n",
    "                    continue\n",
    "                histogram = HdrHistogram(MIN_LATENCY_USEC, MAX_LATENCY_USEC, LATENCY_SIGNIFICANT_DIGITS)\n",
    "                latencies = loaded_data[\"latency\"]\n",
    "                for l in latencies:\n",
    "                    histogram.record_value(l)\n",
    "                histograms[gc].append(histogram)\n",
    "    # Process data\n",
    "    print(f'[{bench}] Processing...')\n",
    "    percentile_list = []\n",
    "    for gc, hists in histograms.items():\n",
    "        for j, histogram in enumerate(hists):\n",
    "            for i in histogram.get_percentile_iterator(5):\n",
    "                percentile_list.append({\"GC\": gc, \"inv\": j, \"value\": i.value_iterated_to, \"percentile\": i.percentile_level_iterated_to / 100})\n",
    "    percentile_df = pandas.DataFrame(percentile_list)\n",
    "    percentile_df[\"other\"] = 1 / (1 - percentile_df[\"percentile\"])\n",
    "    # Plot curves\n",
    "    print(f'[{bench}] Plotting...')\n",
    "    fig, ax = plt.subplots(1,1,figsize=(16,12))\n",
    "    # fig.suptitle(f'{bench} {latency_type} latency')\n",
    "    sns.color_palette()\n",
    "    # colors = ['green', 'blue', 'orange', 'red'][:len(gcs)]\n",
    "    # print(f'{gcs} {colors}')\n",
    "    sns.lineplot(data=percentile_df, x=\"other\", y=\"value\", hue=\"GC\")\n",
    "    # sns.lineplot(data=percentile_df, x=\"other\", y=\"value\", hue=\"GC\")\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Percentile', fontsize=26, labelpad=12)\n",
    "    ax.set_ylabel('Latency (msec)', fontsize=26, labelpad=12)\n",
    "    ax.set_xticks([1, 10, 100, 1000, 10000, 100000, 1000000])\n",
    "    ax.set_xticklabels(['0', '90', '99', '99.9', '99.99', '99.999', '99.9999'], fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda x, pos: f'{int(x / 1000)}'.format(x)))\n",
    "    plt.legend(fontsize=26)\n",
    "\n",
    "    if save is not None:\n",
    "        print(f'[{bench}] Save to latency-{bench}.{save}')\n",
    "        plt.savefig(f'latency-{bench}.{save}', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lusearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lusearch] Loading...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c86678e7caac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_data_and_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbench\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lusearch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-c250357ea927>\u001b[0m in \u001b[0;36mload_data_and_plot\u001b[0;34m(bench, data, invocations, save, latency_type)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Clean up inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDATA\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c250357ea927>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Clean up inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDATA\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "load_data_and_plot(bench = 'lusearch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_and_plot(bench = 'cassandra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_and_plot(bench = 'h2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tomcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_and_plot(bench = 'tomcat')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8684cd0abf0265b4869051515e13a732d6d08253b88329340d4f63cf7e8216db"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
